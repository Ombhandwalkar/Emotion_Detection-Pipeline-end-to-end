# Emotion Detection Pipeline - End to End

A comprehensive end-to-end machine learning pipeline for detecting emotions from facial expressions in real-time or from static images.


## ğŸ¯ Overview

This project implements a complete emotion detection system that can identify human emotions from facial expressions. The pipeline includes data preprocessing, model training, evaluation, and deployment components for real-world applications.

The system can detect the following emotions:
- ğŸ˜Š Happy
- ğŸ˜¢ Sad
- ğŸ˜  Angry
- ğŸ˜¨ Fear
- ğŸ˜® Surprise
- ğŸ˜ Neutral
- ğŸ¤¢ Disgust

## âœ¨ Features

- **End-to-End Pipeline**: Complete workflow from data ingestion to model deployment
- **Real-time Detection**: Process video streams from webcam for live emotion detection
- **Image Processing**: Analyze emotions from static images
- **Pre-trained Models**: Utilize transfer learning for improved accuracy
- **RESTful API**: Flask/FastAPI endpoints for easy integration
- **Web Interface**: User-friendly web application for testing
- **Model Versioning**: Track different model versions and experiments
- **Docker Support**: Containerized deployment for easy scaling

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Ingestion â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing   â”‚
â”‚ - Face Detectionâ”‚
â”‚ - Normalization â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Training  â”‚
â”‚ - CNN/ResNet    â”‚
â”‚ - Transfer Learnâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Evaluation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Deployment    â”‚
â”‚ - API Service   â”‚
â”‚ - Web App       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager
- Virtual environment (recommended)

### Setup Instructions

1. Clone the repository:
```bash
git clone https://github.com/Ombhandwalkar/Emotion_Detection-Pipeline-end-to-end.git
cd Emotion_Detection-Pipeline-end-to-end
```

2. Create and activate virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install required dependencies:
```bash
pip install -r requirements.txt
```

4. Download pre-trained models (if applicable):
```bash
python download_models.py
```

## ğŸ’» Usage

### Training the Model

```bash
python train.py --config config/config.yaml
```

### Running Inference

**On Images:**
```bash
python predict.py --image path/to/image.jpg
```

**On Webcam (Real-time):**
```bash
python live_detection.py
```

**On Video File:**
```bash
python predict.py --video path/to/video.mp4
```

### Starting the Web Application

```bash
python app.py
```
Then navigate to `http://localhost:5000` in your browser.

### Using the API

Start the API server:
```bash
uvicorn api.main:app --reload
```

Example API request:
```python
import requests

url = "http://localhost:8000/predict"
files = {"file": open("image.jpg", "rb")}
response = requests.post(url, files=files)
print(response.json())
```

## ğŸ“Š Dataset

The model is trained on facial emotion recognition datasets such as:
- **FER2013**: 35,887 grayscale images of faces
- **CK+**: Extended Cohn-Kanade dataset
- **AffectNet**: Large-scale database

### Data Preparation

Place your dataset in the following structure:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ sad/
â”‚   â”œâ”€â”€ angry/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ sad/
â”‚   â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ happy/
    â”œâ”€â”€ sad/
    â””â”€â”€ ...
```

## ğŸ§  Model Training

### Training Configuration

Modify `config/config.yaml` to adjust hyperparameters:
```yaml
model:
  architecture: "ResNet50"
  input_size: [48, 48]
  num_classes: 7

training:
  batch_size: 32
  epochs: 50
  learning_rate: 0.001
  optimizer: "Adam"
```

### Model Architecture

The pipeline supports multiple architectures:
- Custom CNN
- ResNet50
- VGG16
- MobileNetV2
- EfficientNet

## ğŸ“ Project Structure

```
Emotion_Detection-Pipeline-end-to-end/
â”‚
â”œâ”€â”€ data/                      # Dataset directory
â”œâ”€â”€ models/                    # Saved models
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for EDA
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                  # Data loading and preprocessing
â”‚   â”œâ”€â”€ models/                # Model architectures
â”‚   â”œâ”€â”€ training/              # Training scripts
â”‚   â”œâ”€â”€ inference/             # Prediction scripts
â”‚   â””â”€â”€ utils/                 # Helper functions
â”œâ”€â”€ api/                       # API endpoints
â”œâ”€â”€ static/                    # Static files for web app
â”œâ”€â”€ templates/                 # HTML templates
â”œâ”€â”€ config/                    # Configuration files
â”œâ”€â”€ tests/                     # Unit tests
â”œâ”€â”€ app.py                     # Flask/FastAPI application
â”œâ”€â”€ train.py                   # Training script
â”œâ”€â”€ predict.py                 # Inference script
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Dockerfile                 # Docker configuration
â””â”€â”€ README.md                  # Project documentation
```

## ğŸ› ï¸ Technologies Used

- **Deep Learning**: TensorFlow/Keras, PyTorch
- **Computer Vision**: OpenCV, PIL
- **Face Detection**: Haar Cascades, MTCNN, Dlib
- **Web Framework**: Flask/FastAPI
- **API Documentation**: Swagger/OpenAPI
- **Deployment**: Docker
- **Model Tracking**: MLflow, Weights & Biases
- **Data Processing**: NumPy, Pandas
- **Visualization**: Matplotlib, Seaborn

## ğŸ“ˆ Results

### Model Performance

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| CNN   | 65.2%    | 64.8%     | 65.0%  | 64.9%    |
| ResNet50 | 72.3% | 71.9%     | 72.1%  | 72.0%    |
| Custom | 68.7%   | 68.3%     | 68.5%  | 68.4%    |

### Confusion Matrix

[Add confusion matrix visualization here]

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a new branch (`git checkout -b feature/improvement`)
3. Make your changes
4. Commit your changes (`git commit -am 'Add new feature'`)
5. Push to the branch (`git push origin feature/improvement`)
6. Create a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Om Bhandwalkar**

- GitHub: [@Ombhandwalkar](https://github.com/Ombhandwalkar)

## ğŸ™ Acknowledgments

- Thanks to the creators of FER2013 and other emotion datasets
- OpenCV community for excellent computer vision tools
- TensorFlow/PyTorch teams for deep learning frameworks

## ğŸ“§ Contact

For questions or feedback, please open an issue or reach out via GitHub.

---

â­ If you found this project helpful, please give it a star!
